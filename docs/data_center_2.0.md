# Data Center 2.0 èªªæ˜æ–‡ä»¶

---

## ğŸŒŸ ç³»çµ±ç›®æ¨™

Data Center 2.0 çµ±ä¸€ç®¡ç†è·è»Šä¸‹æ³¨ç³»çµ±çš„åŸºç¤è³‡æ–™èˆ‡ç‰¹å¾µè™•ç†ï¼Œ
ç¢ºä¿è³‡æ–™å­˜å–ä¸€è‡´ã€å¿«å–æ•ˆèƒ½æœ€ä½³åŒ–ï¼Œä¸¦æ”¯æ´å¾ŒçºŒæ¨è«–èˆ‡è¨“ç·´æµç¨‹ã€‚

**ç®¡ç†ç¯„åœï¼š**
- è·è»Šæ­·å²è³‡æ–™ï¼ˆ`game_log.csv`ï¼‰
- Q-learning æ¨¡å‹ï¼ˆ`q_table.pkl`ï¼‰
- ç‰¹å¾µå·¥ç¨‹ï¼ˆå¦‚ `diff`, `rolling_sum_5`, `wine_type`ï¼‰
- è³‡æ–™å¿«å–èˆ‡æ›´æ–°æ§åˆ¶

---

## ğŸ“‚ æ¨¡çµ„çµæ§‹

| æ¨¡çµ„/æª”æ¡ˆ | åŠŸèƒ½èªªæ˜ |
|:---|:---|
| `data_facade.py` | ç£ç¢Ÿå­˜å–ã€è³‡æ–™å¿«å–ã€è³‡æ–™å¢åŠ  |
| `feature_builder.py` | æä¾›ç‰¹å¾µæ¬„ä½å»ºæ§‹å·¥å…· |
| `data_errors.py` | è³‡æ–™å±¤éŒ¯èª¤å®šç¾© |
| `global_data.py` | Session å¿«å–ç®¡ç†å±¤ |

---

## âš™ï¸ DataFacade åŠŸèƒ½

| æ–¹æ³• | èªªæ˜ |
|:---|:---|
| `game_log()` | è®€å– game_logï¼Œå¿«å–ç®¡ç† |
| `q_table(model_name)` | è®€å–æŒ‡å®šæ¨¡å‹çš„ Q-table |
| `list_models()` | åˆ—å‡º models è³‡æ–™å¤¾çš„æ‰€æœ‰æ¨¡å‹ |
| `append_game_log(new_entry)` | å¢åŠ æ–°ä¸‹æ³¨è³‡æ–™ |
| `build_features(df)` | å°å¤–æä¾›ç‰¹å¾µå»ºæ§‹ |
| `refresh_cache(key)` | æ¸…é™¤å–®ä¸€å¿«å– |
| `clear_all_cache()` | æ¸…ç©ºå…¨éƒ¨å¿«å– |
| `register_on_data_updated(callback)` | è¨»å†Šè³‡æ–™æ›´æ–°é€šçŸ¥ |
| `_notify_data_updated()` | å‘¼å«è³‡æ–™æ›´æ–°é€šçŸ¥ |

---

## ğŸ§ è³‡æ–™æµè¨­è¨ˆï¼ˆæ¨è«–èˆ‡è¨“ç·´ï¼‰

---

### ğŸ“ˆ æ¨è«–ï¼ˆPredictï¼‰è³‡æ–™æµç¯„ä¾‹

å¾æœ€æ–° game_log é æ¸¬ä¸‹ä¸€æ¬¡è¡Œå‹•ï¼š

```python
from data.global_data import Session
from data.feature_builder import FeatureBuilder

# å–å¾—æœ€æ–°è³‡æ–™
game_log = Session.get("game_log")
features = FeatureBuilder.build_features(game_log)

# å–æœ€æ–°ä¸€ç­†ç‰¹å¾µ
last_row = features.iloc[-1]
diff = last_row["diff"]
rolling_sum_5 = last_row["rolling_sum_5"]

# æ‹¿å– Q è¡¨
q_table = Session.get("q_table")
state = (diff, rolling_sum_5)

# é æ¸¬å‹•ä½œ
if state in q_table:
    action_values = q_table[state]
    action = max(action_values, key=action_values.get)
else:
    action = "æŠ¼å°è»Š"

print(f"å»ºè­°å‹•ä½œï¼š{action}")
```

---

### ğŸŒŸ è¨“ç·´ï¼ˆTrainï¼‰è³‡æ–™æµç¯„ä¾‹

å¾å…¨é«” game_log è¨“ç·´æ–°çš„ Q-learning æ¨¡å‹ï¼š

```python
from data.global_data import Session
from data.feature_builder import FeatureBuilder
from agent.trainer import QLearner

# å–å¾—è¨“ç·´è³‡æ–™
game_log = Session.get("game_log")
features = FeatureBuilder.build_features(game_log)

# çµ„è£è¨“ç·´è³‡æ–™
training_data = []

for idx in range(len(features) - 1):
    current = features.iloc[idx]
    next_row = features.iloc[idx + 1]

    state = (current["diff"], current["rolling_sum_5"])
    action = ...      # æ ¹æ“šä¸‹æ³¨ç´€éŒ„æ¨æ–¹
    reward = ...      # æ ¹æ“šå‹è² çµæœè¨ˆç®—
    next_state = (next_row["diff"], next_row["rolling_sum_5"])

    training_data.append((state, action, reward, next_state))

# è¨“ç·´æ¨¡å‹
qlearner = QLearner()

for state, action, reward, next_state in training_data:
    qlearner.learn(state, action, reward, next_state)

# å„²å­˜æ–°æ¨¡å‹
qlearner.save("./data/models/q_model_0501.pkl")
```

---

## ğŸ“š æ•¸æ“šè™•ç†è¦ç¯„

- è³‡æ–™å–ç”¨ï¼šçµ±ä¸€ä½¿ç”¨ `Session.get("game_log")`, `Session.get("q_table")`
- ç‰¹å¾µè™•ç†ï¼šä¸ç›´æ¥ä¿®æ”¹ Sessionï¼Œåœ¨æœ¬åœ°è½‰æ›
- è³‡æ–™å¢åŠ ï¼šä½¿ç”¨ `append_game_log()`ï¼Œä¸¦æ‰‹å‹• `Session.refresh()`
- ç‰¹å¾µå¸¸é§ï¼šæœ‰éœ€è¦æ™‚å¯åœ¨ Session å…§å¢åŠ ç‰¹å¾µ cache

---

## ğŸ›¡ï¸ ä¾‹å¤–éŒ¯èª¤è™•ç†

| éŒ¯èª¤é¡åˆ¥ | èªªæ˜ |
|:---|:---|
| `DataLoadError` | è®€å–æª”æ¡ˆå¤±æ•—æˆ–è³‡æ–™éŒ¯èª¤æ™‚æŠ½å‡º |
| `DataFormatError` | å¿…è¦æ¬„ä½ç¼ºå¤±æˆ–è³‡æ–™çµæ§‹ä¸ç¬¦æ™‚æŠ½å‡º |

---

## ğŸš€ æœªä¾†æ“´å……æ–¹å‘

- æ”¯æ´ fuzzy è§€æ¸¬ç‰¹å¾µï¼ˆ`fuzzy_rules`ï¼‰
- å¢åŠ  state é¢¨éšªå±¤ç´šï¼ˆ`state_risk_level`ï¼‰
- è³‡æ–™å¿«å–è‡ªå‹•å¤±æ•ˆèˆ‡ refresh æ©Ÿåˆ¶
- æ¨¡å‹è¨“ç·´è‡ªå‹•åŒ–ï¼ˆAutoTrainerï¼‰

---


